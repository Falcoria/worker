[program:worker_nmap_scan_queue]
; Name of the program, shown in process lists and logs
command = celery -A app.tasks worker -l INFO -c 1 -Q nmap_scan_queue -n nmap_scan_queue@%%h
; Command to start the Celery worker for the scan queue
directory = %(here)s
; Use current directory as working dir
startsecs = 5
; Wait 5 seconds before considering the process started
autostart = true
; Start automatically when supervisord starts
autorestart = true
; Restart the process if it crashes
stopwaitsecs = 300
; Wait up to 300 seconds for graceful stop before killing
stderr_logfile = /dev/stderr
; Log STDERR output to container’s stderr
stderr_logfile_maxbytes = 0
; Do not limit size of stderr log
stdout_logfile = /dev/stdout
; Log STDOUT output to container’s stdout
stdout_logfile_maxbytes = 0
; Do not limit size of stdout log

[program:worker_nmap_cancel_queue]
; Configuration for the cancel queue worker
command = celery -A app.tasks worker -l INFO -c 1 -Q nmap_cancel_queue -n nmap_cancel_queue@%%h
directory = %(here)s
startsecs = 5
autostart = true
autorestart = true
stopwaitsecs = 300
stderr_logfile = /dev/stderr
stderr_logfile_maxbytes = 0
stdout_logfile = /dev/stdout
stdout_logfile_maxbytes = 0

[program:worker_service_broadcast]
command = celery -A app.tasks worker -l INFO -c 1 -Q worker_service_broadcast -n worker_service_broadcast@%%h
directory = %(here)s
startsecs = 5
autostart = true
autorestart = true
stopwaitsecs = 300
stderr_logfile = /dev/stderr
stderr_logfile_maxbytes = 0
stdout_logfile = /dev/stdout
stdout_logfile_maxbytes = 0

[supervisord]
; Global supervisord configuration
loglevel = info
; Set log level to "info"
nodaemon = true
; Run in foreground (required in Docker)
pidfile = /tmp/supervisord.pid
; Location of the PID file
logfile = /dev/null
; Discard supervisord's own log (Docker handles logs)
logfile_maxbytes = 0
; Prevent any size limit on supervisord’s own log
